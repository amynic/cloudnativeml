{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST CNN & Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for CNN model code\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "print(\"tensorflow Version is: \" + str(tf.__version__))\n",
    "\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "print(os.environ['KERAS_BACKEND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import utils, losses, optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no. of classes\n",
    "num_classes = 10\n",
    "\n",
    "# batch size and training iterations (epochs)\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "#input image dimensions\n",
    "img_rows,img_cols = 28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for train and testing\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(x_train.shape, 'train set')\n",
    "print(x_test.shape, 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"Top\",          # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Jumper\",       # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Trainer\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample image\n",
    "img_index=100\n",
    "label_index = y_train[img_index]\n",
    "plt.figure(0)\n",
    "plt.imshow(x_train[img_index])\n",
    "print('Label Index: ' + str(label_index) + \" Fashion Labels: \" + (fashion_mnist_labels[label_index]))\n",
    "plt.savefig('sampleimage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type convert and scale the test and training data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#one-hot encoding\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test,  num_classes)\n",
    "\n",
    "#formatting issues for depth of image (greyscale = 1) with different kernels (tensorflow, cntk, etc)\n",
    "if K.image_data_format()== 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n",
    "    input_shape = (img_rows, img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras CNN model architecture\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile - how to measure loss\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#train the model and return loss and accuracy for each epoch - history dictionary\n",
    "start = time.time()\n",
    "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model on the test data\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Loss: ', score[0])\n",
    "print('Test Accuracy: ', score[1])\n",
    "print('Time to run: ', (end-start))\n",
    "\n",
    "model.save('fmm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Vs Validation Accuracy graph\n",
    "epoch_list = list(range(1, len(hist.history['accuracy']) + 1))\n",
    "plt.figure(1)\n",
    "plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
    "plt.legend(('Training Accuracy', \"Validation Accuracy\"))\n",
    "plt.show()\n",
    "plt.savefig('TrainingVsValidationAccuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Vs Validation Loss graph\n",
    "epoch_list = list(range(1, len(hist.history['loss']) + 1))\n",
    "plt.figure(2)\n",
    "plt.plot(epoch_list, hist.history['loss'], epoch_list, hist.history['val_loss'])\n",
    "plt.legend(('Training Loss', \"Validation Loss\"))\n",
    "plt.show()\n",
    "plt.savefig('TrainingVsValidationLoss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions on test data\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "plt.figure(3)\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(predictions[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output image for test dataset\n",
    "plt.savefig('TestData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "y_prediction = np.zeros(shape = (10000,10))\n",
    "\n",
    "count = 0\n",
    "for x in y_pred:\n",
    "    index = np.argmax(x)\n",
    "    y_prediction[count, index] = 1\n",
    "    count = count + 1\n",
    "\n",
    "# Create confusion matrix\n",
    "print(fashion_mnist_labels)\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_prediction.argmax(axis=1))\n",
    "print(cm)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "res = ax.imshow(cm, interpolation='nearest')\n",
    "plt.savefig('CorrelationMatrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
